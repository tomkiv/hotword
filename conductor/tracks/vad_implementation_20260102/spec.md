# Specification: Voice Activity Detection (VAD)\n\n## Overview\nThis track implements a lightweight Voice Activity Detection (VAD) system to act as a gatekeeper for the heavy neural network inference. By detecting whether human speech is present in an audio chunk before running the CNN/RNN, we significantly reduce CPU usage and decrease the likelihood of false positives triggered by stationary background noise.\n\n## Functional Requirements\n- **Hybrid VAD Algorithm:** Implement a VAD that uses both Energy (RMS) and Zero-Crossing Rate (ZCR) to distinguish speech from noise.\n- **Inference Gating:** Integrate the VAD into `pkg/engine.Engine` to skip feature extraction and model forward pass when speech is not present.\n- **Hangover Logic:** Implement a configurable "hangover" period (default 300ms) to ensure the engine continues processing for a short time after speech ends, preventing truncation of the hotword.\n- **Threshold Calibration:** Add CLI flags and configuration options for `vad_energy_threshold` and `vad_zcr_threshold`.\n\n## Implementation Details\n- **Package:** Create `pkg/audio/vad.go`.\n- **Calculation:**\n  - Energy: Mean square of samples in the current chunk.\n  - ZCR: Count of sign changes in the signal divided by chunk length.\n- **Engine Integration:** `Engine.Process` will first call `vad.IsSpeech(samples)`. If false and the hangover timer has expired, return a zero confidence score immediately.\n\n## Acceptance Criteria\n- CPU usage of the `listen` command drops significantly when in a quiet environment.\n- The system remains just as responsive to the hotword as it was without VAD.\n- stationary noise (like a fan or computer hum) is correctly identified as "not speech" by the ZCR and energy thresholds.
