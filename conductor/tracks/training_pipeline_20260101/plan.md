# Plan: Training Pipeline\n\n## Phase 1: Gradients and Loss\n- [x] Task: Implement Binary Cross-Entropy (BCE) Loss (b891f88)\n  - [ ] Write tests for BCE loss and its gradient\n  - [ ] Implement loss logic in `pkg/model`\n- [x] Task: Implement Backward Pass for Dense Layer (552b471)\n  - [ ] Write tests for Dense layer gradient calculation\n  - [ ] Implement Backward logic\n- [x] Task: Implement Backward Pass for ReLU and MaxPool2D (a763c01)\n  - [ ] Write tests for activation and pooling gradients\n  - [ ] Implement Backward logic\n- [ ] Task: Implement Backward Pass for Conv2D Layer\n  - [ ] Write tests for Convolutional layer gradients\n  - [ ] Implement Backward logic\n- [ ] Task: Conductor - User Manual Verification 'Phase 1: Gradients and Loss' (Protocol in workflow.md)\n\n## Phase 2: Optimization and Dataset\n- [ ] Task: Implement SGD Optimizer\n  - [ ] Write tests for weight updates with a known learning rate\n  - [ ] Implement Optimizer in `pkg/model`\n- [ ] Task: Implement Dataset Loader\n  - [ ] Write tests for directory crawling and WAV-to-Feature conversion\n  - [ ] Implement Dataset in `pkg/train`\n- [ ] Task: Implement Audio Augmentation (Noise Mixing)\n  - [ ] Write tests for mixing two audio buffers with varying ratios\n  - [ ] Implement augmentation in `pkg/audio`\n- [ ] Task: Conductor - User Manual Verification 'Phase 2: Optimization and Dataset' (Protocol in workflow.md)\n\n## Phase 3: Training Loop Integration\n- [ ] Task: Implement the Trainer\n  - [ ] Write tests for a single training step (forward/backward/update)\n  - [ ] Implement full training loop with epoch management in `pkg/train`\n- [ ] Task: Conductor - User Manual Verification 'Phase 3: Training Loop Integration' (Protocol in workflow.md)
