# Plan: Training Pipeline\n\n## Phase 1: Gradients and Loss [checkpoint: 1bd4e52]\n- [x] Task: Implement Binary Cross-Entropy (BCE) Loss (b891f88)\n  - [ ] Write tests for BCE loss and its gradient\n  - [ ] Implement loss logic in `pkg/model`\n- [x] Task: Implement Backward Pass for Dense Layer (552b471)\n  - [ ] Write tests for Dense layer gradient calculation\n  - [ ] Implement Backward logic\n- [x] Task: Implement Backward Pass for ReLU and MaxPool2D (a763c01)\n  - [ ] Write tests for activation and pooling gradients\n  - [ ] Implement Backward logic\n- [x] Task: Implement Backward Pass for Conv2D Layer (3c4eff3)\n  - [ ] Write tests for Convolutional layer gradients\n  - [ ] Implement Backward logic\n- [x] Task: Conductor - User Manual Verification 'Phase 1: Gradients and Loss' (Protocol in workflow.md) (1bd4e52)\n\n## Phase 2: Optimization and Dataset [checkpoint: 532c913]\n- [x] Task: Implement SGD Optimizer (6a8c52f)\n  - [ ] Write tests for weight updates with a known learning rate\n  - [ ] Implement Optimizer in `pkg/model`\n- [x] Task: Implement Dataset Loader (8cb4c7f)\n  - [ ] Write tests for directory crawling and WAV-to-Feature conversion\n  - [ ] Implement Dataset in `pkg/train`\n- [x] Task: Implement Audio Augmentation (Noise Mixing) (de15313)\n  - [ ] Write tests for mixing two audio buffers with varying ratios\n  - [ ] Implement augmentation in `pkg/audio`\n- [x] Task: Conductor - User Manual Verification 'Phase 2: Optimization and Dataset' (Protocol in workflow.md) (532c913)\n\n## Phase 3: Training Loop Integration [checkpoint: 1888829]\n- [x] Task: Implement the Trainer (bf379a0)\n  - [ ] Write tests for a single training step (forward/backward/update)\n  - [ ] Implement full training loop with epoch management in `pkg/train`\n- [x] Task: Conductor - User Manual Verification 'Phase 3: Training Loop Integration' (Protocol in workflow.md) (1888829)
